{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcb649a-9aa5-49fc-bd23-2de0c47dd8b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from utils import predict_and_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d45d4fa-b4d3-40bd-b417-dd878a1f3d42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_data.csv\")\n",
    "test_df = pd.read_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44d5402-55a0-4541-b8c8-f7093ea59037",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b378dd01-c694-4930-8a14-0ddb42838358",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692bd1f4-c4b6-473a-975e-9ece520f1320",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008b3df3-3731-4ffd-b784-dd62f4e9ccf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create X_train, X_test, y_train, y_test for ease of use\n",
    "X_train = train_df.drop('Class', axis=1)\n",
    "y_train = train_df['Class']\n",
    "\n",
    "X_test = test_df.drop('Class', axis=1)\n",
    "y_test = test_df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde50a55-285e-4389-a312-e58b53226ca8",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "Hyperparameter tuning refers to the shaping of the model architecture from the available space. This, in simple words, is nothing but searching for the right hyperparameter to find high precision and accuracy. Two of the most widely-used parameter optimiser techniques are:\n",
    "\n",
    "1. Grid search\n",
    "2. Random search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c023f5ef-2678-4087-be82-0211e380705a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Grid Search\n",
    "\n",
    " - In this tuning technique, we simply build a model for every combination of various hyperparameters and evaluate each model. The model which gives the highest accuracy wins.\n",
    " - The pattern followed here is similar to the grid, where all the values are placed in the form of a matrix.\n",
    " - Each set of parameters is taken into consideration and the accuracy is noted.\n",
    " - Once all the combinations are evaluated, the model with the set of parameters which give the top accuracy is considered to be the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c179ca0-0c51-4f31-863d-4e352486d2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples of Parameter Matrix\n",
    "\n",
    "# # Parameter matrix for Random Forest\n",
    "# rf_params = {'n_estimators': [100, 200, 300, 500, 800],\n",
    "#                'max_features': ['sqrt', 'log2'],\n",
    "#                'max_depth': [8, 10, 20],\n",
    "#                'min_samples_split': [2, 5, 10]\n",
    "#               }\n",
    "\n",
    "# # Parameter matrix for Gradient Boost\n",
    "# gbm_params = {  \"n_estimators\":[100,150,200],\n",
    "#                 \"learning_rate\": [0.01, 0.025, 0.05],\n",
    "#                 \"max_depth\":[3,5],\n",
    "#                 \"subsample\":[ 0.8, 0.9,1.0], \n",
    "#             }\n",
    "\n",
    "# # Parameter matrix for XGBoost\n",
    "# xgb_params = {'n_estimators' : [100,400,800],\n",
    "#          \"learning_rate\"    : [0.01,0.05, 0.10] ,\n",
    "#          \"max_depth\"        : [ 3, 5, 7, 13],\n",
    "#          \"min_child_weight\" : [ 3, 5],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a1ee9b-c2cd-4450-b7bf-a710606e11de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580161d9-81ad-4b61-9dfd-1d32f5f12432",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_params = {'n_estimators' : [100, 200],\n",
    "              \"max_depth\"    : [ 3, 4],\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73060520-73ba-4fc0-a0c6-eec59561a6ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gs_xgb = GridSearchCV(estimator= XGBClassifier(), \n",
    "                        param_grid= xgb_params, \n",
    "                        n_jobs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b63872-a4a5-48eb-8d94-ba8a16c31578",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gs_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f543c616-90de-4d59-a219-48021dac1230",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gs_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c715ac39-0275-41a3-bf79-d9ea68354d58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gs_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1490754-73aa-41bb-95b2-9f9098be4268",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predictons\n",
    "xgb_gs_hpo = predict_and_evaluate(gs_xgb.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f9e47a-ee76-4390-a260-a12fe697fd03",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e87772c-06c4-4fd5-8500-0221236cc8a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "Random search is a technique where random combinations of the hyperparameters are used to find the best solution for the built model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a39608-44ad-4a74-8362-e52904cb173a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd574e46-fd6b-4b33-b685-032cad5ef74b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rs_xgb = RandomizedSearchCV(estimator= XGBClassifier(), \n",
    "                        param_distributions = xgb_params,\n",
    "                        n_iter= 2,\n",
    "                        n_jobs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3275a1b-db62-40ef-9574-a93ea7035c63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%time rs_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669632c0-b547-4119-9275-bba4bebd11a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rs_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1c9b06-06a8-46ed-8a05-c2c4d5311e71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rs_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d74c9d1-dacd-4c8a-bb71-a74e634b8720",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predictons\n",
    "xgb_rs_hpo = predict_and_evaluate(gs_xgb.best_estimator_, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
