{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection\n",
    "It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of data\n",
    "\n",
    "- The datasets contains transactions made by credit cards in September 2013 by european cardholders.\n",
    "- This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions.\n",
    "- The dataset is highly <b>unbalanced</b>, the positive class (frauds) account for 0.172% of all transactions.\n",
    "- It contains only numerical input variables which are the result of a PCA transformation. \n",
    "- Due to confidentiality issues, the original features and more background information about the data is not provided. \n",
    "- Features V1, V2, … V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. \n",
    "- Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset.\n",
    "- The feature 'Amount' is the transaction Amount.\n",
    "- Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
    "\n",
    "Source: [Kaggle](https://www.kaggle.com/mlg-ulb/creditcardfraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For scaling the features and train-test split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "# For model buidling\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# For hyper-paramter tuning\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from utils import predict_and_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read data file\n",
    "# this file is compressed in bzip2 format and index column is included in it\n",
    "df = pd.read_csv('/media/abhishek/589E61B39E618A783/C-DAC Document/Practical Machine Learning/PML/Code/Dataset/creditcard.csv')\n",
    "#df = pd.read_csv('CC.csv.bz2',\n",
    " #                compression='bz2',\n",
    "  #               index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##  Undersand the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() # Check Null Values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Frauds 99.83 % of the dataset\n",
      "Frauds 0.17 % of the dataset\n"
     ]
    }
   ],
   "source": [
    "# Check Distribution Of Label\n",
    "print('No Frauds', round(df['Class'].value_counts()[0]/len(df) * 100,2), '% of the dataset')\n",
    "print('Frauds', round(df['Class'].value_counts()[1]/len(df) * 100,2), '% of the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Frauds 284315 are normal transactions\n",
      "Frauds 492 are fraud\n"
     ]
    }
   ],
   "source": [
    "# The classes are heavily skewed. This is problem that needs to be solved. How?\n",
    "print('No Frauds', round(df['Class'].value_counts()[0],2), 'are normal transactions')\n",
    "print('Frauds', round(df['Class'].value_counts()[1],2), 'are fraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhishek/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Class Distributions \\n (0: No Fraud || 1: Fraud)')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = [\"#0101DF\", \"#DF0101\"]\n",
    "\n",
    "sns.countplot('Class', data=df, palette=colors)\n",
    "plt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Notice how imbalanced is our original dataset! \n",
    "- Most of the transactions are non-fraud. \n",
    "- If we use this dataframe as the base for our predictive models and analysis we might get a lot of errors and our algorithms will probably overfit since it will \"assume\" that most transactions are not fraud. \n",
    "- But we don't want our model to assume, we want our model to detect patterns that give signs of fraud!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocessing - Scaling and Distribution\n",
    "- We will first scale the columns comprise of <b>Time</b> and <b>Amount </b>. \n",
    "- Time and amount should be scaled as the other columns. \n",
    "- On the other hand, we need to also create a sub sample of the dataframe in order to have an equal amount of Fraud and Non-Fraud cases, helping our algorithms better understand patterns that determines whether a transaction is a fraud or not.\n",
    "\n",
    "### What is a sub-Sample?\n",
    "In this scenario, our subsample will be a dataframe with a 50/50 ratio of fraud and non-fraud transactions. Meaning our sub-sample will have the same amount of fraud and non fraud transactions.\n",
    "\n",
    "### Why do we create a sub-Sample?\n",
    "We saw that the original dataframe is heavily imbalanced! Using the original dataframe  will cause the following issues:\n",
    "<ul>\n",
    "<li><b>Overfitting: </b>Our classification models will assume that in most cases there are no frauds! What we want for our model is to be certain when a fraud occurs. </li>\n",
    "<li><b>Wrong Correlations:</b> Although we don't know what the \"V\" features stand for, it will be useful to understand how each of this features influence the result (Fraud or No Fraud) by having an imbalance dataframe we are not able to see the true correlations between the class and features. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Scaling\n",
    "\n",
    "The **StandardScaler** assumes your data is normally distributed within each feature and will scale them such that the distribution is now centred around 0, with a standard deviation of 1. \n",
    "\n",
    "$$\\frac{\\text{x}-\\text{mean}}{\\text{standard deviation}}$$\n",
    "\n",
    "The **MinMaxScaler** is the probably the most famous scaling algorithm, and follows the following formula for each feature. \n",
    "\n",
    "$$\\frac{\\text{x}-\\text{min}}{\\text{max}-\\text{min}}$$\n",
    "\n",
    "It essentially shrinks the range such that the range is now between 0 and 1 (or -1 to 1 if there are negative values). If the distribution is not Gaussian or the standard deviation is very small, the min-max scaler works better. However, it is sensitive to outliers, so if there are outliers in the data, you might want to consider the Robust Scaler below.\n",
    "\n",
    "**Robust Scaler** scale features using statistics that are robust to outliers. The RobustScaler uses a similar method to the Min-Max scaler but it instead uses the interquartile range, rathar than the min-max, so that it is robust to outliers. \n",
    "\n",
    "$$\\frac{\\text{x}-\\text{Q1(x)}}{\\text{Q3(x)}-\\text{Q1(x)}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Since most of our data has already been scaled, we will scale the columns that are not scaled (Amount and Time)\n",
    "# RobustScaler is less prone to outliers.\n",
    "rob_scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop(['Amount'], axis=1, inplace=True) # remove original time and Amount Columns from df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>scaled_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>1.783274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.269825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>4.983721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>1.418291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>0.670579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Class  scaled_amount  \n",
       "0 -0.189115  0.133558 -0.021053      0       1.783274  \n",
       "1  0.125895 -0.008983  0.014724      0      -0.269825  \n",
       "2 -0.139097 -0.055353 -0.059752      0       4.983721  \n",
       "3 -0.221929  0.062723  0.061458      0       1.418291  \n",
       "4  0.502292  0.219422  0.215153      0       0.670579  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rearranging the columns\n",
    "scaled_amount = df['scaled_amount']\n",
    "\n",
    "df.drop(['scaled_amount'], axis=1, inplace=True)\n",
    "df.insert(0, 'scaled_amount', scaled_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.783274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.269825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.983721</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.418291</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.670579</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   scaled_amount  Time        V1        V2        V3        V4        V5  \\\n",
       "0       1.783274   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321   \n",
       "1      -0.269825   0.0  1.191857  0.266151  0.166480  0.448154  0.060018   \n",
       "2       4.983721   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198   \n",
       "3       1.418291   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4       0.670579   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193   \n",
       "\n",
       "         V6        V7        V8  ...       V20       V21       V22       V23  \\\n",
       "0  0.462388  0.239599  0.098698  ...  0.251412 -0.018307  0.277838 -0.110474   \n",
       "1 -0.082361 -0.078803  0.085102  ... -0.069083 -0.225775 -0.638672  0.101288   \n",
       "2  1.800499  0.791461  0.247676  ...  0.524980  0.247998  0.771679  0.909412   \n",
       "3  1.247203  0.237609  0.377436  ... -0.208038 -0.108300  0.005274 -0.190321   \n",
       "4  0.095921  0.592941 -0.270533  ...  0.408542 -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Amount is Scaled!\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**EXERCISE:** Scale the Time Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Splitting the DataFrame\n",
    "\n",
    "Before proceeding with any <b> Sampling technique</b> we have to separate the orginal dataframe.<br> \n",
    "<b> Why? for testing purposes, we want to test our models on the original testing set not on the testing set created by either of these techniques.</b><br> The main goal is to fit the model either with the dataframes that were undersample and oversample (in order for our models to detect the patterns), and test it on the original testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ss = StratifiedShuffleSplit(n_splits=1,\n",
    "                            test_size=0.2,\n",
    "                            train_size=0.8,\n",
    "                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for train_index, test_index in ss.split(X, y):\n",
    "    train_df = df.iloc[train_index]\n",
    "    test_df = df.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributions: \n",
      "\n",
      "Train Set\n",
      "0    227451\n",
      "1       394\n",
      "Name: Class, dtype: int64\n",
      "\n",
      "Test Set\n",
      "0    56864\n",
      "1       98\n",
      "Name: Class, dtype: int64\n",
      "\n",
      "Percentage:\n",
      "\n",
      "Train Set\n",
      "0    99.827075\n",
      "1     0.172925\n",
      "Name: Class, dtype: float64\n",
      "\n",
      "Test Set\n",
      "0    99.827955\n",
      "1     0.172045\n",
      "Name: Class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Distributions: \\n')\n",
    "print(\"Train Set\")\n",
    "print(train_df.Class.value_counts())\n",
    "print(\"\\nTest Set\")\n",
    "print(test_df.Class.value_counts())\n",
    "print(\"\\nPercentage:\")\n",
    "print(\"\\nTrain Set\")\n",
    "print((train_df.Class.value_counts()/ len(train_df))*100)\n",
    "print(\"\\nTest Set\")\n",
    "print((test_df.Class.value_counts()/ len(test_df))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Random Under-Sampling:\n",
    "\n",
    "Implement *\"Random Under Sampling\"* which basically consists of removing data in order to have a more <b> balanced dataset </b> and thus avoiding our models to overfitting.\n",
    "\n",
    "**Steps:**\n",
    "<ul>\n",
    "<li>The first thing we have to do is determine how <b>imbalanced</b> is our class (use \"value_counts()\" on the class column to determine the amount for each label)  </li>\n",
    "<li>Once we determine how many instances are considered <b>fraud transactions </b> (Fraud = \"1\") , we should bring the <b>non-fraud transactions</b> to the same amount as fraud transactions (assuming we want a 50/50 ratio), this will be equivalent to 492 cases of fraud and 492 cases of non-fraud transactions.  </li>\n",
    "<li> After implementing this technique, we have a sub-sample of our dataframe with a 50/50 ratio with regards to our classes. Then the next step we will implement is to <b>shuffle the data</b> to see if our models can maintain a certain accuracy everytime we run this script.</li>\n",
    "</ul>\n",
    "\n",
    "**Note:** The main issue with \"Random Under-Sampling\" is that we run the risk that our classification models will not perform as accurate as we would like to since there is a great deal of <b>information loss</b> (randomly picking 394 non-fraud transaction  from 2,27,451 non-fraud transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lets shuffle the data before creating the subsamples\n",
    "train_df = train_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# amount of fraud classes 394 rows\n",
    "fraud_df = train_df.loc[train_df['Class'] == 1]\n",
    "non_fraud_df = train_df.loc[train_df['Class'] == 0][:394]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# As fraud_df and non_fraud_df are concatenated, Shuffle dataframe rows to mix the rows\n",
    "df2 = normal_distributed_df.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(788, 31)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136146</th>\n",
       "      <td>1.252987</td>\n",
       "      <td>81568.0</td>\n",
       "      <td>-0.943243</td>\n",
       "      <td>1.414152</td>\n",
       "      <td>1.025925</td>\n",
       "      <td>0.921129</td>\n",
       "      <td>-0.519709</td>\n",
       "      <td>-0.482484</td>\n",
       "      <td>0.537591</td>\n",
       "      <td>-1.765457</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.330298</td>\n",
       "      <td>1.611345</td>\n",
       "      <td>-0.032397</td>\n",
       "      <td>-0.081072</td>\n",
       "      <td>0.705869</td>\n",
       "      <td>-0.254197</td>\n",
       "      <td>-0.322509</td>\n",
       "      <td>0.583576</td>\n",
       "      <td>0.204309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237107</th>\n",
       "      <td>-0.307413</td>\n",
       "      <td>149096.0</td>\n",
       "      <td>1.184891</td>\n",
       "      <td>3.152084</td>\n",
       "      <td>-6.134780</td>\n",
       "      <td>5.531252</td>\n",
       "      <td>1.733867</td>\n",
       "      <td>-1.816861</td>\n",
       "      <td>-0.916696</td>\n",
       "      <td>0.265568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336442</td>\n",
       "      <td>0.124236</td>\n",
       "      <td>-0.823865</td>\n",
       "      <td>-0.079887</td>\n",
       "      <td>0.028828</td>\n",
       "      <td>0.389711</td>\n",
       "      <td>0.060171</td>\n",
       "      <td>0.485187</td>\n",
       "      <td>0.326552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15166</th>\n",
       "      <td>1.089779</td>\n",
       "      <td>26523.0</td>\n",
       "      <td>-18.474868</td>\n",
       "      <td>11.586381</td>\n",
       "      <td>-21.402917</td>\n",
       "      <td>6.038515</td>\n",
       "      <td>-14.451158</td>\n",
       "      <td>-4.146524</td>\n",
       "      <td>-14.856124</td>\n",
       "      <td>12.431140</td>\n",
       "      <td>...</td>\n",
       "      <td>1.577924</td>\n",
       "      <td>1.741136</td>\n",
       "      <td>-1.251138</td>\n",
       "      <td>-0.396219</td>\n",
       "      <td>0.095706</td>\n",
       "      <td>1.322751</td>\n",
       "      <td>-0.217955</td>\n",
       "      <td>1.628793</td>\n",
       "      <td>0.482248</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120505</th>\n",
       "      <td>1.087822</td>\n",
       "      <td>75851.0</td>\n",
       "      <td>-4.793667</td>\n",
       "      <td>3.418911</td>\n",
       "      <td>-5.074445</td>\n",
       "      <td>4.035987</td>\n",
       "      <td>-3.527875</td>\n",
       "      <td>-1.923242</td>\n",
       "      <td>-5.065981</td>\n",
       "      <td>1.996885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342122</td>\n",
       "      <td>1.168618</td>\n",
       "      <td>0.289531</td>\n",
       "      <td>-0.371888</td>\n",
       "      <td>0.144761</td>\n",
       "      <td>0.084735</td>\n",
       "      <td>-0.197431</td>\n",
       "      <td>0.328672</td>\n",
       "      <td>0.835395</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42784</th>\n",
       "      <td>0.328233</td>\n",
       "      <td>41243.0</td>\n",
       "      <td>-10.940739</td>\n",
       "      <td>6.261586</td>\n",
       "      <td>-14.182339</td>\n",
       "      <td>7.183602</td>\n",
       "      <td>-9.951363</td>\n",
       "      <td>-3.860820</td>\n",
       "      <td>-13.547302</td>\n",
       "      <td>7.096472</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088342</td>\n",
       "      <td>2.267448</td>\n",
       "      <td>-0.492029</td>\n",
       "      <td>-0.239303</td>\n",
       "      <td>0.454368</td>\n",
       "      <td>-0.101611</td>\n",
       "      <td>0.446997</td>\n",
       "      <td>0.062293</td>\n",
       "      <td>-0.439770</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        scaled_amount      Time         V1         V2         V3        V4  \\\n",
       "136146       1.252987   81568.0  -0.943243   1.414152   1.025925  0.921129   \n",
       "237107      -0.307413  149096.0   1.184891   3.152084  -6.134780  5.531252   \n",
       "15166        1.089779   26523.0 -18.474868  11.586381 -21.402917  6.038515   \n",
       "120505       1.087822   75851.0  -4.793667   3.418911  -5.074445  4.035987   \n",
       "42784        0.328233   41243.0 -10.940739   6.261586 -14.182339  7.183602   \n",
       "\n",
       "               V5        V6         V7         V8  ...       V20       V21  \\\n",
       "136146  -0.519709 -0.482484   0.537591  -1.765457  ... -0.330298  1.611345   \n",
       "237107   1.733867 -1.816861  -0.916696   0.265568  ...  0.336442  0.124236   \n",
       "15166  -14.451158 -4.146524 -14.856124  12.431140  ...  1.577924  1.741136   \n",
       "120505  -3.527875 -1.923242  -5.065981   1.996885  ...  0.342122  1.168618   \n",
       "42784   -9.951363 -3.860820 -13.547302   7.096472  ... -0.088342  2.267448   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "136146 -0.032397 -0.081072  0.705869 -0.254197 -0.322509  0.583576  0.204309   \n",
       "237107 -0.823865 -0.079887  0.028828  0.389711  0.060171  0.485187  0.326552   \n",
       "15166  -1.251138 -0.396219  0.095706  1.322751 -0.217955  1.628793  0.482248   \n",
       "120505  0.289531 -0.371888  0.144761  0.084735 -0.197431  0.328672  0.835395   \n",
       "42784  -0.492029 -0.239303  0.454368 -0.101611  0.446997  0.062293 -0.439770   \n",
       "\n",
       "        Class  \n",
       "136146      0  \n",
       "237107      1  \n",
       "15166       1  \n",
       "120505      1  \n",
       "42784       1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  Equally Distributing \n",
    "<a id=\"correlating\"></a>\n",
    "Now that we have our dataframe correctly balanced, we can go further with our <b>analysis</b> and <b>data preprocessing</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of the Classes in the subsample dataset\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: Class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Distribution of the Classes in the subsample dataset')\n",
    "print(df2['Class'].value_counts()/len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhishek/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = [\"#0101DF\", \"#DF0101\"]\n",
    "sns.countplot('Class', data=df2, palette=colors)\n",
    "plt.title('Equally Distributed Classes', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training the ML Model for Fraud Detection(Classification) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create X_train, X_test, y_train, y_test for ease of use\n",
    "X_train = df2.drop('Class', axis=1)\n",
    "y_train = df2['Class']\n",
    "\n",
    "X_test = test_df.drop('Class', axis=1)\n",
    "y_test = test_df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100, criterion=\"entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_features='auto',\n",
       "                       random_state=502461585)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree in the Forest\n",
    "rf_clf.estimators_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Evaluation Metrics\n",
    "The Given the class imbalance ratio, Confusion matrix and accuracy is not meaningful\n",
    "for unbalanced classification. A robust evaluation is required to measure the\n",
    "performance of a fraud detection model.\n",
    "\n",
    "**1. False Positives:**\n",
    "A false positive is an outcome where the model incorrectly predicts the positive class.\n",
    "<br>**2. False Negatives:**\n",
    "A false negative is an outcome where the model incorrectly predicts the negative class.\n",
    "<br>**3. Precision:**\n",
    "Precision talks about how precise/accurate the model is i.e. out of those predicted positives, how many of them are actual positive. Precision is a good measure to determine, when the costs of False Positives is high. For instance, here, a false positive means that a transaction is that is non- fraudulent has been identified as fraudulent. This can happen if the precision is not high for the fraud detection model.\n",
    "<br>**4. Recall:**\n",
    "Recall calculates how many of the Actual Positives our model captures through labeling it as Positive (True Positive). If a fraudulent transaction is predicted as non-fraudulent (Predicted Negative), the consequence can be very bad for the bank.\n",
    "<br>**5. F1 Score:**\n",
    "F1 Score is used to seek a balance between Precision and Recall.\n",
    "<br>**6. Mathews Correlation Coefficient:**\n",
    "The coefficient takes into account true and false positives and negatives and is generally regarded as a balanced measure which can be used even if the classes are of very different sizes. The MCC is in essence a correlation coefficient between the observed and predicted binary classifications; it returns a value between −1 and +1.<br> \n",
    "A coefficient of +1 represents a perfect prediction, 0 no better than random prediction and −1 indicates total disagreement between prediction and observation.<br>\n",
    "The Matthews correlation coefficient is more informative than F1 score and\n",
    "accuracy in evaluating binary classification problems, because it takes into\n",
    "account the balance ratios of the four confusion matrix categories (true\n",
    "positives, true negatives, false positives, and false negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Algorithm             </th><th style=\"text-align: right;\">  False Positives</th><th style=\"text-align: right;\">  False Negatives</th><th style=\"text-align: right;\">  Precision</th><th style=\"text-align: right;\">  Recall</th><th style=\"text-align: right;\">  F1 Score</th><th style=\"text-align: right;\">  MCC</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>RandomForestClassifier</td><td style=\"text-align: right;\">             1353</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">       0.06</td><td style=\"text-align: right;\">    0.93</td><td style=\"text-align: right;\">      0.12</td><td style=\"text-align: right;\"> 0.24</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_res = predict_and_evaluate(rf_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Feature Importances\n",
    "\n",
    "In order to quantify the usefulness of all the variables in the entire random forest, we can look at the relative importances of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01244265, 0.00733936, 0.01166053, 0.02078205, 0.03151352,\n",
       "       0.09828645, 0.00978751, 0.00925737, 0.02700175, 0.01360403,\n",
       "       0.02161712, 0.1490109 , 0.07828769, 0.0694116 , 0.00965604,\n",
       "       0.18857429, 0.00823737, 0.0447671 , 0.06965463, 0.02050534,\n",
       "       0.01312417, 0.01531758, 0.0116005 , 0.008162  , 0.00602726,\n",
       "       0.00693028, 0.0073316 , 0.01123306, 0.0116543 , 0.00722194])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(rf_clf.feature_importances_, index=X_train.columns)\n",
    "feature_importances.sort_values(ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V14              0.188574\n",
       "V10              0.149011\n",
       "V4               0.098286\n",
       "V11              0.078288\n",
       "V17              0.069655\n",
       "V12              0.069412\n",
       "V16              0.044767\n",
       "V3               0.031514\n",
       "V7               0.027002\n",
       "V9               0.021617\n",
       "V2               0.020782\n",
       "V18              0.020505\n",
       "V20              0.015318\n",
       "V8               0.013604\n",
       "V19              0.013124\n",
       "scaled_amount    0.012443\n",
       "V1               0.011661\n",
       "V27              0.011654\n",
       "V21              0.011600\n",
       "V26              0.011233\n",
       "V5               0.009788\n",
       "V13              0.009656\n",
       "V6               0.009257\n",
       "V15              0.008237\n",
       "V22              0.008162\n",
       "Time             0.007339\n",
       "V25              0.007332\n",
       "V28              0.007222\n",
       "V24              0.006930\n",
       "V23              0.006027\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,4), dpi=100)\n",
    "feature_importances.plot.bar()\n",
    "plt.title(\"Feature importances using MDI\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Mean Decrease in Impurity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**EXERCISE:** Train RF model again by considering only important features (e.g. top 10) and evaluate the model and observe the difference in the metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gbm_clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Algorithm                 </th><th style=\"text-align: right;\">  False Positives</th><th style=\"text-align: right;\">  False Negatives</th><th style=\"text-align: right;\">  Precision</th><th style=\"text-align: right;\">  Recall</th><th style=\"text-align: right;\">  F1 Score</th><th style=\"text-align: right;\">  MCC</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>GradientBoostingClassifier</td><td style=\"text-align: right;\">             2495</td><td style=\"text-align: right;\">                8</td><td style=\"text-align: right;\">       0.03</td><td style=\"text-align: right;\">    0.92</td><td style=\"text-align: right;\">      0.07</td><td style=\"text-align: right;\"> 0.17</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gbm_res = predict_and_evaluate(gbm_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhishek/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:14:53] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Algorithm    </th><th style=\"text-align: right;\">  False Positives</th><th style=\"text-align: right;\">  False Negatives</th><th style=\"text-align: right;\">  Precision</th><th style=\"text-align: right;\">  Recall</th><th style=\"text-align: right;\">  F1 Score</th><th style=\"text-align: right;\">  MCC</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>XGBClassifier</td><td style=\"text-align: right;\">             2299</td><td style=\"text-align: right;\">                7</td><td style=\"text-align: right;\">       0.04</td><td style=\"text-align: right;\">    0.93</td><td style=\"text-align: right;\">      0.07</td><td style=\"text-align: right;\"> 0.18</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_res = predict_and_evaluate(xgb_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm_clf = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm_res = predict_and_evaluate(svm_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Comparing the metrics for all the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(data=[rf_res, gbm_res, xgb_res, svm_res], \n",
    "             columns=('Algorithm','False Positives', \n",
    "                      'False Negatives', 'Precision', \n",
    "                      'Recall', 'F1 Score', 'MCC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
